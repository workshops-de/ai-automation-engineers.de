---
layout: '../../../layouts/BlogLayout.astro'
title: 'Millionen private Daten in KI-Trainingssets entdeckt: Der DataComp-Skandal erschÃ¼ttert die AI-Community'
description: 'Forscher finden Millionen sensibler Dokumente in KI-Trainingssets - von ReisepÃ¤ssen bis Kreditkarten. Was bedeutet das fÃ¼r uns alle?'
pubDate: '2025-08-05'
author: 'Robin BÃ¶hm'
tags: ['AI', 'Ethics & AI', 'Datenschutz', 'Machine Learning', 'DSGVO']
category: 'Ethics & AI'
readTime: '12 min read'
image: 'https://images.pexels.com/photos/1181452/pexels-photo-1181452.jpeg?auto=compress&cs=tinysrgb&w=1200&h=600&dpr=2'
---

**TL;DR:** Forscher der Carnegie Mellon University haben im DataComp CommonPool - einem der grÃ¶ÃŸten Open-Source-DatensÃ¤tze fÃ¼r KI-Bildgeneratoren - Millionen von sensiblen persÃ¶nlichen Dokumenten entdeckt. Darunter: ReisepÃ¤sse, Kreditkarten, Geburtsurkunden und Ã¼ber 800 validierte LebenslÃ¤ufe mit hochpersÃ¶nlichen Informationen. Das Brisante: Die Daten wurden bereits millionenfach heruntergeladen und kÃ¶nnten in zahlreichen KI-Modellen stecken.

Stell dir vor, du findest deinen Reisepass, deine Kreditkarte oder sogar die Geburtsurkunde deiner Kinder in einem Ã¶ffentlich zugÃ¤nglichen KI-Trainingsdatensatz. Science Fiction? Leider nein - das ist die erschreckende RealitÃ¤t, die Forscher jetzt aufgedeckt haben.

## Die wichtigsten Fakten

- ğŸ“… **Zeitraum der Datensammlung**: 2014-2022 (vor der ChatGPT-Ã„ra!)
- ğŸ’¾ **Datensatz-GrÃ¶ÃŸe**: 12,8 Milliarden Bild-Text-Paare
- ğŸ” **Untersuchter Anteil**: Nur 0,1% des gesamten Datensatzes
- ğŸ˜± **GeschÃ¤tzte Betroffene**: Hunderte Millionen sensible Dokumente
- ğŸ“¥ **Downloads**: Ãœber 2 Millionen Mal in 2 Jahren
- ğŸ¤– **Potenziell betroffene Modelle**: Stable Diffusion, Midjourney und viele mehr

## Was ist neu?

Die Forscher um Rachel Hong und William Agnew von der Carnegie Mellon University haben ihre Ergebnisse in einer [Studie auf arXiv](https://arxiv.org/pdf/2506.17185) verÃ¶ffentlicht. Die Entdeckung ist ein Weckruf fÃ¼r die gesamte KI-Industrie.

### Kernfunde im Ãœberblick

**PersÃ¶nliche Dokumente en masse**
- Tausende validierte Kreditkarten, FÃ¼hrerscheine und ReisepÃ¤sse
- Ãœber 800 bestÃ¤tigte LebenslÃ¤ufe mit vollstÃ¤ndigen Kontaktdaten
- Geburtsurkunden von Kindern mit Gesundheitsinformationen
- Bewerbungsunterlagen inklusive HintergrundÃ¼berprÃ¼fungen

**Versagende SchutzmaÃŸnahmen**
- Automatische Gesichtserkennung Ã¼bersah geschÃ¤tzte 102 Millionen Gesichter
- Keine Filter fÃ¼r bekannte PII-Muster (E-Mail-Adressen, Sozialversicherungsnummern)
- Unkenntlichmachung funktionierte nur teilweise

## Technische Details

Der DataComp CommonPool basiert auf Web-Scraping-Daten der gemeinnÃ¼tzigen Organisation Common Crawl. Die Ironie: Die Kuratoren wussten um die Problematik und versuchten, GegenmaÃŸnahmen zu ergreifen.

```python
# So kÃ¶nnte ein PII-Filter aussehen - der aber NICHT implementiert wurde
def filter_pii(text):
    # E-Mail-Adressen
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    # Sozialversicherungsnummern (US-Format)
    ssn_pattern = r'\b\d{3}-\d{2}-\d{4}\b'
    # Kreditkartennummern
    cc_pattern = r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b'
    # Aber: Diese Filter wurden offenbar nicht oder nur unzureichend eingesetzt
```

### Vergleich mit bestehenden DatensÃ¤tzen

| Feature | DataComp CommonPool | LAION-5B | ProprietÃ¤re DatensÃ¤tze |
|---------|-------------------|----------|------------------------|
| GrÃ¶ÃŸe | 12,8 Milliarden | 5,85 Milliarden | Unbekannt |
| PII-Filter | âŒ Unzureichend | âŒ Minimal | â“ Intransparent |
| Gesichtserkennung | âœ… Teilweise | âŒ | â“ |
| Lizenz | Akademisch (aber kommerziell nutzbar) | Open Source | ProprietÃ¤r |
| Downloads | 2+ Millionen | Millionen | N/A |

## Was bedeutet das fÃ¼r die Praxis?

### FÃ¼r Entwickler
- **Sofortige ÃœberprÃ¼fung**: Checke deine verwendeten DatensÃ¤tze auf PII
- **Neue Filter implementieren**: Robuste PII-Erkennung ist ein Muss
- **Dokumentation**: Transparenz Ã¼ber Datenquellen wird kritisch

### FÃ¼r Unternehmen
- **Compliance-Risiko**: DSGVO-VerstÃ¶ÃŸe kÃ¶nnen teuer werden (bis zu 4% des Jahresumsatzes)
- **Reputationsschaden**: "Wir haben aus Versehen Ihre Kreditkarte trainiert" ist kein guter PR-Slogan
- **Technische Schulden**: Modelle mÃ¼ssen mÃ¶glicherweise neu trainiert werden

## Das Problem mit der Zustimmung

Das Perfide: Die meisten Daten stammen aus der Zeit vor 2020 - bevor ChatGPT die Welt verÃ¤nderte. 

> "Ich lade vielleicht etwas einmal ins Internet hoch und mÃ¶chte es dann ein Jahr spÃ¤ter wieder lÃ¶schen, aber dann hat diese LÃ¶schung keine Wirkung mehr"
> â€” William Agnew, Carnegie Mellon University

Die Menschen konnten schlicht nicht zustimmen, dass ihre Daten fÃ¼r KI-Training verwendet werden - diese Technologie war den meisten damals vÃ¶llig unbekannt.

## Human-in-the-Loop als Sicherheitsnetz

**Kritische Regel: Automatisierung ist gut, menschliche Kontrolle ist besser.**

Was hier wirklich fehlt:
- Manuelle Stichprobenkontrollen der DatensÃ¤tze
- Ethik-Reviews vor VerÃ¶ffentlichung
- Klare Verantwortlichkeiten fÃ¼r Datenschutz
- Opt-out-Mechanismen, die wirklich funktionieren

## Stimmen aus der Community

> "Das zeigt wirklich die UrsÃ¼nde von KI-Systemen, die auf Ã¶ffentlichen Daten basieren"
> â€” Ben Winters, Consumer Federation of America

> "Es ist einfach so, dass alle groÃŸangelegten Web-Scraping-DatensÃ¤tze immer Inhalte enthalten, die da nicht drin sein sollten"
> â€” Abeba Birhane, Trinity College Dublin

## Roadmap & Ausblick

**Q3 2025**: Erwartete verschÃ¤rfte EU-Regulierungen fÃ¼r KI-Trainingssets
**Q4 2025**: MÃ¶gliche technische Standards fÃ¼r PII-Filterung
**2026**: Neue Generation "privacy-first" Trainingssets?

## VerfÃ¼gbarkeit & Tools

- **Hugging Face PII-Tool**: [Opt-out fÃ¼r zukÃ¼nftige Downloads](https://huggingface.co/) (hilft aber nicht rÃ¼ckwirkend)
- **DataComp CommonPool**: Weiterhin Ã¶ffentlich verfÃ¼gbar
- **Forschungspapier**: [arXiv:2506.17185](https://arxiv.org/pdf/2506.17185)

## Quick Links & Ressourcen

- ğŸ“š [Original-Studie der Carnegie Mellon University](https://arxiv.org/pdf/2506.17185)
- ğŸ™ [DataComp GitHub Repository](https://github.com/mlfoundations/datacomp)
- ğŸ’¬ [Diskussion auf HackerNews](https://news.ycombinator.com/)
- ğŸ“° [MIT Technology Review Artikel](https://www.technologyreview.com/)

## Fazit

Die Entdeckung von Millionen sensibler Dokumente im DataComp CommonPool ist ein Weckruf fÃ¼r die gesamte KI-Industrie. Es zeigt deutlich: Die aktuelle Praxis des wahllosen Web-Scrapings ist nicht nur ethisch fragwÃ¼rdig, sondern verstÃ¶ÃŸt hÃ¶chstwahrscheinlich gegen geltende Datenschutzgesetze.

Die Herausforderung ist gewaltig: Wie entfernt man Daten aus Modellen, die bereits trainiert wurden? Wie verhindert man zukÃ¼nftige Datenschutzverletzungen? Und wie schaffen wir ein Gleichgewicht zwischen Innovation und PrivatsphÃ¤re?

**Next Steps fÃ¼r Entwickler und Unternehmen:**
1. ÃœberprÃ¼fe sofort deine verwendeten Trainingssets auf PII
2. Implementiere robuste Filterungsmechanismen
3. Erstelle klare Datenschutz-Richtlinien fÃ¼r KI-Projekte
4. Plane fÃ¼r mÃ¶gliche Neu-Trainings deiner Modelle

Die Zukunft der KI hÃ¤ngt davon ab, ob wir diese Herausforderungen meistern. Es ist Zeit, Verantwortung zu Ã¼bernehmen - bevor die nÃ¤chste Datenschutzkatastrophe passiert. ğŸ›¡ï¸

---

*Letzte Aktualisierung: 05. August 2025*
*Quellen: arXiv.org, MIT Technology Review, Carnegie Mellon University*